import numpy as np
import os

{% if dataFile_inputsScaler != 'None' %}
from sklearn.preprocessing import {{ dataFile_inputsScaler }}
{% endif %}
{% if dataFile_outputsScaler != 'None' and dataFile_outputsScaler != dataFile_inputsScaler %}
from sklearn.preprocessing import {{ dataFile_outputsScaler }}
{% endif %}

def read_data(path, **kwargs):
    return np.genfromtxt(
        path,
        delimiter=',',
        skip_header={{ 1 if columnInfo_hasHeaderRow else 0 }},
        **kwargs
    )


{% if dataFile_appMode == 'classification' or dataFile_appMode == 'regression' %}
def read_data_and_encode_output_column(path, column_types):
    from sklearn.preprocessing import LabelEncoder
    _DATA_TYPE = np.float

    def save_encoding_file(encoder):
        from pykern import pkjson
        from pykern.pkcollections import PKDict
        pkjson.dump_pretty(
            PKDict(
                zip(
                    encoder.transform(encoder.classes_).astype(_DATA_TYPE).tolist(),
                    encoder.classes_,
                ),
            ),
            filename='{{ classificationOutputColEncodingFile }}',
        )

    v = read_data(path, dtype=None, encoding='utf=8')
    if len(v.dtype.descr) > 1:
        descr = v.dtype.descr
        output_encoding = None
        for idx in range(len(descr)):
            ft = descr[idx]
            if np.dtype(ft[1]).kind == 'U':
                if column_types[idx] == 'none':
                    v[ft[0]] = 0
                    descr[idx] = (ft[0], np.float)
                else:
                    encoder = LabelEncoder().fit(v[ft[0]])
                    v[ft[0]] = encoder.transform(v[ft[0]])
                    descr[idx] = (ft[0], _DATA_TYPE)
                    if output_encoding is None and column_types[idx] == 'output':
                        output_encoding = encoder
        v = np.array(v.astype(descr).tolist())
        if output_encoding:
            save_encoding_file(output_encoding)
    return v
{% endif %}

def scale_columns(values, column_types, col_type, scaler):
    columns = list(filter(lambda idx: column_types[idx] == col_type, range(len(column_types))))
    if scaler and len(columns):
        values[:, columns] = scaler().fit_transform(values[:, columns])
    return columns


def scale_file(path, column_types, inputs_scaler, outputs_scaler):
    {% if dataFile_appMode == 'classification' or dataFile_appMode == 'regression' %}
    v = read_data_and_encode_output_column(path, column_types)
    {% else %}
    v = read_data(path)
    {% endif %}
    in_idx = scale_columns(v, column_types, 'input', inputs_scaler)
    out_idx = scale_columns(v, column_types, 'output', outputs_scaler)
    os.remove(path)
    np.save('{{ scaledFile }}', v)
    return v, in_idx, out_idx


scaled, in_idx, out_idx = scale_file(
    '{{ dataFile }}',
    {{ columnTypes }},
    {{ dataFile_inputsScaler }},
{% if dataFile_appMode == 'classification' %}
    None,
{% else %}
    {{ dataFile_outputsScaler }},
{% endif %}
)
