import numpy as np
import keras.losses
from keras.callbacks import CSVLogger
from pykern.pkcollections import PKDict
{% if image_data %}

model.compile(
    optimizer='adam',
    loss={{ neuralNet_losses }},
    metrics=['accuracy'],
)
try:
    history = model.fit(
        split.train_gen,
        validation_data=split.val_gen,
        epochs={{ neuralNet_epochs }},
        callbacks=[CSVLogger('fit.csv')],
    )
except Exception as e:
    raise AssertionError(f"Model training failed due to:{e.message}")
{% else %}

model.compile(
    loss={{ neuralNet_losses }},
    optimizer='{{ neuralNet_optimizer }}'
)
model.fit(
    x=train[:, in_idx],
    y=train[:, out_idx],
    validation_data=(validate[:, in_idx], validate[:, out_idx]),
    batch_size={{ neuralNet_batch_size }},
    shuffle={% if neuralNet_shuffle == '1' %}True{% else %}False{% endif %},
    epochs={{ neuralNet_epochs }},
    verbose=False,
    callbacks=[CSVLogger('{{ fitCSVFile }}')],
)
testy = test[:, out_idx]
testx = test[:, in_idx]

{% endif %}

{% if image_data %}
def _domain_len(outputs_true):
    return len(numpy.unique(outputs_true))

def _prediction_shape(prediction, testy):
    return prediction.shape[-1] == _domain_len(testy)

def _classification_case(prediction, testy):
    return {{ discreteOutputs }} and _prediction_shape(prediction, testy)

def _predictions_final(predictions, testy):
    p = predictions
    print("pre check p.shape=", p.shape)
    print("pre check testy.shape=", testy.shape)
    if _classification_case(predictions, testy):
        p = np.argmax(predictions, axis=1)
    {# TODO (gurhar1133) argmax or something for image to image predictions? #}
    if {{ imageToImage }}:
        p = numpy.array([numpy.expand_dims(numpy.argmax(x, axis=-1), axis=-1) for x in predictions]).flatten()
        {# p = np.argmax(predictions, axis=1).flatten() #}
    return p

def _predictions_initial(testx, testy):
    if split.test_gen.outScaler:
        t = split.test_gen.outScaler.inverse_transform(testy)
        return PKDict(
            p=split.test_gen.outScaler.inverse_transform(model.predict(testx)),
            testy=t.flatten() if {{ imageToImage }} else t,
        )
    return PKDict(
        p=model.predict(x=testx),
        testy=np.array(testy).flatten() if {{ imageToImage }} else testy,
    )

o = _predictions_initial(testx, testy)
p = _predictions_final(o.p, o.testy)
print(p.shape)
print(o.testy.shape)
{% else %}
p = model.predict(x=testx)
{% endif %}
model.save('{{ weightedFile }}')
np.save('{{ testFile }}', o.testy)
np.save('{{ predictFile }}', p)
