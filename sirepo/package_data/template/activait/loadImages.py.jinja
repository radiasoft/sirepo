from pykern.pkcollections import PKDict
from sklearn.model_selection import train_test_split
import h5py
import keras
import math
import numpy


class SirepoHDF5Sequence(keras.utils.Sequence):
    def __init__(
        self,
        filename,
        x,
        y,
        indices,
        shuffle,
        batch_size,
    ):
        self.filename = filename
        self.x = x
        self.y = y
        self.indices = indices
        self.batch_size = batch_size
        self.shuffle = shuffle

    def __len__(self):
        return math.ceil(len(self.indices) / self.batch_size)

    def _scale(self, domain, values):
        if not domain:
            return values
        d = domain[1] - domain[0]
        return (values - domain[0]) / d

    def __getitem__(self, idx):
        indices = numpy.sort(
            self.indices[idx * self.batch_size : (idx + 1) * self.batch_size]
        )
        with h5py.File(self.filename, "r", libver="latest", swmr=True) as f:
            x = f[self.x.key][indices]
            y = f[self.y.key][indices]
            if not x.any() and y.any():
                raise AssertionError(f"Empty batch: x={x} y={y}")
            return self._scale(self.x.domain, x), self._scale(self.y.domain, y)

    def on_epoch_end(self):
        if self.shuffle:
            numpy.random.shuffle(self.indices)


def _split_indices(indices_all):
    test_and_validate = (100 - {{partition_training}}) / 100
    validation_size = ((test_and_validate * 100) - {{partition_testing}}) / 100
    train_indices, tvx, _, tvy = train_test_split(
        indices_all, indices_all, test_size=test_and_validate, random_state=42, shuffle=True
    )
    test_indices, val_indices, _, _ = train_test_split(
        tvx, tvy, test_size=validation_size/test_and_validate, random_state=42, shuffle=True
    )
    return PKDict(
        train=train_indices,
        val=val_indices,
        test=test_indices,
    )


def image_train_val_test_split(
    **kwargs
):
    with h5py.File(kwargs.get("src"), "r", libver="latest", swmr=True) as file:
        indices_all = numpy.arange(file[kwargs.get("X_key")].shape[0])
        d = [numpy.min(file['{{ inPath }}']), numpy.max(file['{{ inPath }}'])]
    s = _split_indices(indices_all)
    r = PKDict()
    for k in s:
        r[k+"_gen"] = SirepoHDF5Sequence(
            filename=kwargs.get('src'),
            x=PKDict(
                domain=d,
                key=kwargs.get('X_key'),
            ),
            y=PKDict(
                domain=None,
                key=kwargs.get('y_key'),
            ),
            indices=s[k],
            batch_size=kwargs.get('batch_size'),
            shuffle=kwargs.get('shuffle'),
        )
    return r


output_shape = {{ outputShape }}
split = image_train_val_test_split(
    src='{{ dataFile }}',
    X_key="{{ inPath }}",
    y_key="{{ outPath }}",
    shuffle={{ shuffleEachEpoch }},
    batch_size={{ neuralNet_batch_size }},
)
with h5py.File('{{ dataFile }}', "r", libver="latest", swmr=True) as file:
    testy = file["{{ outPath }}"][sorted(split.test_gen.indices)]
    input_shape = file["{{ inPath }}"].shape[1:]
    if len(input_shape) < 3:
        input_shape += (1,)
testx = split.test_gen
