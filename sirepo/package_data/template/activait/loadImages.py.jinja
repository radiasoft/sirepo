from pykern.pkcollections import PKDict
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import h5py
import keras
import math
import numpy
{% if inputsScaler != "None" and inputsScaler != "MinMaxScaler" %}
from sklearn.preprocessing import {{ inputsScaler }}
{% endif %}
{% if outputsScaler != "None" and outputsScaler != "MinMaxScaler" %}
from sklearn.preprocessing import {{ outputsScaler }}
{% endif %}

class SirepoScaler:
    def __init__(
        self,
        values,
    ):
        self.columns = 1
        if len(values.shape) == 2:
            self.columns = values.shape[1]
        if self.columns > 1:
            self.domain = []
            for i in range(self.columns):
                self.domain.append(self.__compute_domain(values[:, i]))
        else:
            self.domain = self.__compute_domain(values)

    def _fit(self):
        with h5py.File(self.filename, "r", libver="latest", swmr=True) as f:
            self.original_shape_x = f[self.x.key].shape
            self.channels = self.original_shape_x[-1]
            self.original_shape_y = f[self.y.key].shape
            if self.inScaler:
                self.inScaler.fit(numpy.array(f[self.x.key]).reshape(-1, self.channels))
            if self.outScaler:
                self.outScaler.fit(numpy.array(f[self.y.key]).reshape(-1, 1))

    def scale(self, values):
        if self.columns == 1:
            return self.__scale(values, self.domain)
        values = values[:]
        for i in range(self.columns):
            values[:, i] = self.__scale(values[:, i], self.domain[i])
        return values

    def __compute_domain(self, values):
        # computes min, max, size
        d = [numpy.min(values), numpy.max(values)]
        d.append(d[1] - d[0])
        return d

    def __scale(self, values, domain):
        return (values - domain[0]) / domain[2]


class SirepoHDF5Sequence(keras.utils.Sequence):
    def __init__(
        self,
        filename,
        x,
        y,
        indices,
        shuffle,
        batch_size,
        in_scaler=None,
        out_scaler=None,
    ):
        self.filename = filename
        self.x = x
        self.y = y
        self.indices = indices
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.return_value = None
        self.inScaler = self._scaler(in_scaler)
        self.outScaler = self._scaler(out_scaler)
        self._fit()

    def set_return_value(self, name):
        self.return_value = name
        return self

    def _scaler(self, scaler):
        if scaler is None:
            print(f"scaler is None scaler={scaler}")
            return
        if scaler == MinMaxScaler:
            print("\n\n\n MIN MAX HIT")
            return scaler(feature_range=({{ feature_min }}, {{ feature_max }}))
        return scaler()



    def __len__(self):
        return math.ceil(len(self.indices) / self.batch_size)

    def _scale(self, scaler, values):
        if not scaler:
            return values
        return scaler.scale(values)

    def __getitem__(self, idx):
        indices = numpy.sort(
            self.indices[idx * self.batch_size : (idx + 1) * self.batch_size]
        )
        with h5py.File(self.filename, "r", libver="latest", swmr=True) as f:
            x = f[self.x.key][indices]
            y = f[self.y.key][indices]
            if not x.any() and y.any():
                raise AssertionError(f"Empty batch: x={x} y={y}")
            if self.inScaler:
                x = self.inScaler.transform(numpy.array(x).reshape(-1, self.channels))
                x = x.reshape(len(indices), *self.original_shape_x[1:])
            if self.outScaler:
                y = self.outScaler.transform(y.reshape(-1, 1))
            return (x, y)

    def on_epoch_end(self):
        if self.shuffle and not self.return_value:
            numpy.random.shuffle(self.indices)


def _split_indices(indices_all):
    test_and_validate = (100 - {{partition_training}}) / 100
    validation_size = ((test_and_validate * 100) - {{partition_testing}}) / 100
    train_indices, tvx, _, tvy = train_test_split(
        indices_all,
        indices_all,
        test_size=test_and_validate,
        random_state=42,
        shuffle=True,
    )
    test_indices, val_indices, _, _ = train_test_split(
        tvx,
        tvy,
        test_size=validation_size / test_and_validate,
        random_state=42,
        shuffle=True,
    )
    return PKDict(
        train=train_indices,
        val=val_indices,
        test=test_indices,
    )


def image_train_val_test_split(
    filename,
    xkey,
    ykey,
    shuffle,
    batch_size,
    output_shape,
    **kwargs
):
    with h5py.File(filename, "r") as f:
        indices_all = numpy.arange(f[xkey].shape[0])
        xs = SirepoScaler(f[xkey])
        ys = SirepoScaler(f[ykey])
    s = _split_indices(indices_all)
    r = PKDict()
    for k in s:
        r[k + "_gen"] = SirepoHDF5Sequence(
            filename=filename,
            x=PKDict(
                scaler=xs,
                key=xkey,
            ),
            y=PKDict(
                scaler=ys,
                key=ykey,
            ),
            indices=s[k],
            batch_size=batch_size,
            shuffle=shuffle,
            {% if inputsScaler %}
            in_scaler=kwargs.get('in_scaler'),
            {% endif %}
            {%if outputsScaler %}
            out_scaler=kwargs.get('out_scaler'),
            {% endif %}
        )
    return r


output_shape = {{outputShape}}
split = image_train_val_test_split(
    "{{ dataFile }}",
    "{{ inPath }}",
    "{{ outPath }}",
    {{shuffleEachEpoch}},
    {{neuralNet_batch_size}},
    output_shape,
    {% if inputsScaler %}
    in_scaler={{ inputsScaler }},
    {% endif %}
    {%if outputsScaler %}
    out_scaler={{ outputsScaler }},
    {% endif %}
)
with h5py.File("{{ dataFile }}", "r") as f:
    input_shape = f["{{ inPath }}"].shape[1:]
    if len(input_shape) < 3:
        input_shape += (1,)

testy = []
for y in split.test_gen.set_return_value("y"):
    testy += y.tolist()
testx = split.test_gen.set_return_value("x")
