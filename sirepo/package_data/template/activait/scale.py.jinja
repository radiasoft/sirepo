import numpy as np
import os
import sirepo.numpy
import sirepo.sim_data
from sklearn.preprocessing import MinMaxScaler


{% if dataFile_inputsScaler != 'None' and dataFile_inputsScaler != "MinMaxScaler" %}
from sklearn.preprocessing import {{ dataFile_inputsScaler }}
{% endif %}
{% if dataFile_outputsScaler != 'None' and dataFile_outputsScaler != dataFile_inputsScaler  and dataFile_outputsScaler != "MinMaxScaler" %}
from sklearn.preprocessing import {{ dataFile_outputsScaler }}
{% endif %}

def read_data(data_reader, **kwargs):
    return sirepo.numpy.ndarray_from_generator(
        data_reader.csv_generator(),
        {{ 1 if columnInfo_hasHeaderRow else 0 }},
        **kwargs,
    )


{% if dataFile_appMode == 'classification' or dataFile_appMode == 'regression' %}
def read_data_and_encode_output_column(data_reader, column_types):
    from sklearn.preprocessing import LabelEncoder
    _DATA_TYPE = np.double

    def save_encoding_file(encoder):
        from pykern import pkjson
        from pykern.pkcollections import PKDict
        pkjson.dump_pretty(
            PKDict(
                zip(
                    encoder.transform(encoder.classes_).astype(_DATA_TYPE).tolist(),
                    encoder.classes_,
                ),
            ),
            filename='{{ classificationOutputColEncodingFile }}',
        )

    v = read_data(data_reader, dtype=None, encoding='utf=8')
    if len(v.dtype.descr) > 1:
        descr = v.dtype.descr
        output_encoding = None
        for idx in range(len(descr)):
            ft = descr[idx]
            if np.dtype(ft[1]).kind == 'U':
                if column_types[idx] == 'none':
                    v[ft[0]] = 0
                    descr[idx] = (ft[0], np.double)
                else:
                    encoder = LabelEncoder().fit(v[ft[0]])
                    v[ft[0]] = encoder.transform(v[ft[0]])
                    descr[idx] = (ft[0], _DATA_TYPE)
                    if output_encoding is None and column_types[idx] == 'output':
                        output_encoding = encoder
        v = np.array(v.astype(descr).tolist())
        if output_encoding:
            save_encoding_file(output_encoding)
    return v
{% endif %}

def scale_columns(values, column_types, col_type, scaler):
    columns = list(filter(lambda idx: column_types[idx] == col_type, range(len(column_types))))
    if not len(columns):
        return columns
    if scaler and scaler == MinMaxScaler:
        values[:, columns] = scaler(feature_range=({{ feature_min }}, {{ feature_max }})).fit_transform(values[:, columns])
    if scaler:
        values[:, columns] = scaler().fit_transform(values[:, columns])
    return columns


def scale_file(data_reader, column_types, inputs_scaler, outputs_scaler):
    {% if dataFile_appMode == 'classification' or dataFile_appMode == 'regression' %}
    {% if image_data %}
    v = read_data(data_reader)
    {% else %}
    v = read_data_and_encode_output_column(data_reader, column_types)
    {% endif %}
    {% else %}
    v = read_data(data_reader)
    {% endif %}
    in_idx = scale_columns(v, column_types, 'input', inputs_scaler)
    out_idx = scale_columns(v, column_types, 'output', outputs_scaler)
    os.remove(data_reader.path)
    np.save('{{ scaledFile }}', v)
    return v, in_idx, out_idx


scaled, in_idx, out_idx = scale_file(
    sirepo.sim_data.get_class("activait").activait_data_reader('{{ dataFile }}', '{{ dataPath }}'),
    {{ columnTypes }},
    {{ dataFile_inputsScaler }},
{% if dataFile_appMode == 'classification' %}
    None,
{% else %}
    {{ dataFile_outputsScaler }},
{% endif %}
)

input_shape = (len(in_idx),)
output_shape = len(out_idx)
